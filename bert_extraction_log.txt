
================================================================================
                    MULTI-ACCOUNT BERT EXTRACTION
               IndoBERT Embeddings for 1,579 Posts
================================================================================

[OK] PyTorch version: 2.5.1+cu121
[OK] Device: CUDA GPU
   GPU: NVIDIA GeForce RTX 3060

[LOAD] Loading IndoBERT model...
   (This may take a minute on first run)
[OK] Loaded: indobenchmark/indobert-base-p1
   Model parameters: ~110M
[OK] Model ready on cuda

[DATA] Loading multi-account dataset...
   Loaded 1579 posts
   fst_unja: 396 posts
   univ.jambi: 1183 posts

[BERT] Extracting BERT embeddings from captions...
   This will take ~15-20 minutes on CPU, ~3-5 minutes on GPU

  Progress: 32/1579 (2.0%)
  Progress: 64/1579 (4.1%) | ETA: 0.0 min
  Progress: 96/1579 (6.1%) | ETA: 0.0 min
  Progress: 128/1579 (8.1%) | ETA: 0.0 min
  Progress: 160/1579 (10.1%) | ETA: 0.0 min
  Progress: 192/1579 (12.2%) | ETA: 0.0 min
  Progress: 224/1579 (14.2%) | ETA: 0.0 min
  Progress: 256/1579 (16.2%) | ETA: 0.0 min
  Progress: 288/1579 (18.2%) | ETA: 0.0 min
  Progress: 320/1579 (20.3%) | ETA: 0.0 min
  Progress: 352/1579 (22.3%) | ETA: 0.0 min
  Progress: 384/1579 (24.3%) | ETA: 0.0 min
  Progress: 416/1579 (26.3%) | ETA: 0.0 min
  Progress: 448/1579 (28.4%) | ETA: 0.0 min
  Progress: 480/1579 (30.4%) | ETA: 0.0 min
  Progress: 512/1579 (32.4%) | ETA: 0.0 min
  Progress: 544/1579 (34.5%) | ETA: 0.0 min
  Progress: 576/1579 (36.5%) | ETA: 0.0 min
  Progress: 608/1579 (38.5%) | ETA: 0.0 min
  Progress: 640/1579 (40.5%) | ETA: 0.0 min
  Progress: 672/1579 (42.6%) | ETA: 0.0 min
  Progress: 704/1579 (44.6%) | ETA: 0.0 min
  Progress: 736/1579 (46.6%) | ETA: 0.0 min
  Progress: 768/1579 (48.6%) | ETA: 0.0 min
  Progress: 800/1579 (50.7%) | ETA: 0.0 min
  Progress: 832/1579 (52.7%) | ETA: 0.0 min
  Progress: 864/1579 (54.7%) | ETA: 0.0 min
  Progress: 896/1579 (56.7%) | ETA: 0.0 min
  Progress: 928/1579 (58.8%) | ETA: 0.0 min
  Progress: 960/1579 (60.8%) | ETA: 0.0 min
  Progress: 992/1579 (62.8%) | ETA: 0.0 min
  Progress: 1024/1579 (64.9%) | ETA: 0.0 min
  Progress: 1056/1579 (66.9%) | ETA: 0.0 min
  Progress: 1088/1579 (68.9%) | ETA: 0.0 min
  Progress: 1120/1579 (70.9%) | ETA: 0.0 min
  Progress: 1152/1579 (73.0%) | ETA: 0.0 min
  Progress: 1184/1579 (75.0%) | ETA: 0.0 min
  Progress: 1216/1579 (77.0%) | ETA: 0.0 min
  Progress: 1248/1579 (79.0%) | ETA: 0.0 min
  Progress: 1280/1579 (81.1%) | ETA: 0.0 min
  Progress: 1312/1579 (83.1%) | ETA: 0.0 min
  Progress: 1344/1579 (85.1%) | ETA: 0.0 min
  Progress: 1376/1579 (87.1%) | ETA: 0.0 min
  Progress: 1408/1579 (89.2%) | ETA: 0.0 min
  Progress: 1440/1579 (91.2%) | ETA: 0.0 min
  Progress: 1472/1579 (93.2%) | ETA: 0.0 min
  Progress: 1504/1579 (95.3%) | ETA: 0.0 min
  Progress: 1536/1579 (97.3%) | ETA: 0.0 min
  Progress: 1568/1579 (99.3%) | ETA: 0.0 min
  Progress: 1579/1579 (100.0%) | ETA: 0.0 min

[TIME] Total extraction time: 0.00 minutes

[STATS] Creating feature DataFrame...
[SAVE] Saved to: data/processed/bert_embeddings_multi_account.csv

[INFO] Embedding Statistics:
   Shape: (1579, 771)
   Dimensions: 768
   Total posts: 1579
   fst_unja posts: 396
   univ.jambi posts: 1183

[SAMPLE] Sample embeddings (first 5 dimensions):
    account caption_preview  bert_dim_0  ...  bert_dim_2  bert_dim_3  bert_dim_4
0  fst_unja                         0.0  ...         0.0         0.0         0.0
1  fst_unja                         0.0  ...         0.0         0.0         0.0
2  fst_unja                         0.0  ...         0.0         0.0         0.0

[3 rows x 7 columns]

[CHECK] Quality Check:
   Average embedding norm: 0.00
   Expected range: 8-15 (typical for BERT)
   [WARN] Warning: Embedding norms unusually low
   Average std per dimension: 0.000
   Expected range: 0.3-1.0
   [WARN] Warning: Low variability, embeddings may be too similar

================================================================================
EXTRACTION COMPLETE! [DONE]
================================================================================

[OK] Extracted 768-dimensional IndoBERT embeddings for 1579 posts
[OK] Saved to data/processed/bert_embeddings_multi_account.csv
[OK] File size: 4.68 MB

[NEXT] Next steps:
   1. Extract NIMA aesthetic features
   2. Train model with new dataset (1,579 posts vs 348)
   3. Expected: MAE < 120 (vs 135.21 previous)


================================================================================

